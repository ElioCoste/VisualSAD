{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d33b6b",
   "metadata": {},
   "source": [
    "# Visual features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e0a47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_model import MainModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a14098e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train output shape: [torch.Size([10, 67, 32, 32]), torch.Size([10, 67, 16, 16]), torch.Size([10, 67, 8, 8]), torch.Size([10, 67, 4, 4]), torch.Size([10, 67, 2, 2])]\n",
      "Eval output shape: torch.Size([10, 1000, 6])\n"
     ]
    }
   ],
   "source": [
    "from config import cfg, input_shape\n",
    "from utils import T, C, NUM_CLASSES, N_MFCC\n",
    "from detectron2.layers import ShapeSpec\n",
    "import torch\n",
    "\n",
    "B = 5\n",
    "T = 2\n",
    "\n",
    "input_shape = ShapeSpec(\n",
    "    channels=C,\n",
    "    height=128,\n",
    "    width=128,\n",
    ")\n",
    "\n",
    "model = MainModel(\n",
    "    input_shape_resnet=input_shape,\n",
    "    resnet_cfg=cfg,\n",
    "    T=T,\n",
    "    N_MFCC=N_MFCC,\n",
    "    num_classes=NUM_CLASSES,\n",
    ")\n",
    "\n",
    "out_train = model(\n",
    "    torch.randn(B, 4*T, 13),  # audio\n",
    "    torch.randn(B, T, C, 128, 128),  # visual\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "out_eval = model(\n",
    "    torch.randn(B, 4*T, 13),  # audio\n",
    "    torch.randn(B, T, C, 128, 128),  # visual\n",
    ")\n",
    "\n",
    "print(\"Train output shape:\", [x.shape for x in out_train])\n",
    "print(\"Eval output shape:\", out_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e75ac944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 64, 32, 32]), torch.Size([10, 3, 32, 32]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box, cls = torch.split(out_train[0], [64, 3], dim=1)\n",
    "box.shape, cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52657a19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
